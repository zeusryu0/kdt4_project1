{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import warnings\n",
    "import requests\n",
    "import re\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NYTimes\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import datetime as dt\n",
    "\n",
    "stdt = dt.datetime(2018,9,10)\n",
    "(stdt + relativedelta(months=1)).strftime('%Y%m%d')\n",
    "while stdt < dt.datetime(2022,2,10):\n",
    "    date_lst = []\n",
    "    title_lst = []\n",
    "    summary_lst = []\n",
    "    \n",
    "    start_date = stdt.strftime('%Y%m%d')\n",
    "    stdt = stdt + relativedelta(months=1)\n",
    "    end_date = stdt.strftime('%Y%m%d')\n",
    "    section_lst = ['Business%7Cnyt%3A%2F%2Fsection%2F0415b2b0-513a-5e78-80da-21ab770cb753','World%7Cnyt%3A%2F%2Fsection%2F70e865b6-cc70-5181-84c9-8368b3a5c34b']\n",
    "    #https://www.nytimes.com/search?dropmab=true&endDate=20220214&query=oil%20price&sections=Business%7Cnyt%3A%2F%2Fsection%2F0415b2b0-513a-5e78-80da-21ab770cb753&sort=oldest&startDate=20220101&types=article\n",
    "    for section in section_lst:\n",
    "        url = f'https://www.nytimes.com/search?dropmab=true&endDate={end_date}&query=oil%20price&sections={section}&sort=oldest&startDate={start_date}&types=article'\n",
    "        driver.get(url)\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        while driver.find_elements_by_css_selector('div.css-vsuiox > button'):\n",
    "            driver.find_elements_by_css_selector('div.css-vsuiox > button')[0].click()\n",
    "            time.sleep(1.5)\n",
    "        html = driver.page_source\n",
    "        #print(html[:100])\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        for article in soup.select('#site-content > div > div:nth-child(2) > div > ol > li.css-1l4w6pd'):\n",
    "            if article.select('div > div > p')[0].text == 'DealBook':\n",
    "                continue\n",
    "            title = article.select('div > div > a > h4')[0].text\n",
    "            try :\n",
    "                summary = article.select('div > div > a > p')[0].text\n",
    "            except:\n",
    "                summary = np.nan\n",
    "            date = article.select('div > span')[0].text\n",
    "            \n",
    "            date_lst.append(date)\n",
    "            title_lst.append(title)\n",
    "            summary_lst.append(summary)\n",
    "    df = pd.DataFrame({'date':date_lst,'title':title_lst, 'summary':summary_lst})\n",
    "    df.to_csv(f'./crawling/NYTimes/news_NYT_{start_date}_{end_date}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WP\n",
    "url = 'https://www.washingtonpost.com/search?query=oil%20price&btn-search=&facets=%7B%22time%22%3A%5B1640444400000%2C1644847002340%5D%2C%22sort%22%3A%22relevancy%22%2C%22section%22%3A%5B%22Business%22%5D%2C%22author%22%3A%5B%5D%7D'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "import datetime as dt\n",
    "\n",
    "stdt = dt.datetime(2021,2,10)\n",
    "while stdt < dt.datetime(2022,2,10):\n",
    "    start_date = stdt.strftime('%m/%d/%y')\n",
    "    sd = stdt.strftime('%Y%m%d')\n",
    "    stdt = stdt + relativedelta(months=1)\n",
    "    end_date = stdt.strftime('%m/%d/%y')\n",
    "    ed = stdt.strftime('%Y%m%d')\n",
    "    \n",
    "    title_lst = []\n",
    "    summary_lst = []\n",
    "    date_lst = []\n",
    "\n",
    "    sections = ['World', 'Business','Politics']\n",
    "    for section in sections:\n",
    "        url = f'https://www.washingtonpost.com/search?query=oil%20price&btn-search=&facets=%7B%22time%22%3A%5B1640444400000%2C1644847002340%5D%2C%22sort%22%3A%22relevancy%22%2C%22section%22%3A%5B%22{section}%22%5D%2C%22author%22%3A%5B%5D%7D'\n",
    "        driver.get(url)\n",
    "        time.sleep(2)\n",
    "        driver.find_element_by_xpath('//*[@id=\"main-content\"]/div[1]/section[2]/div[1]/button').click()\n",
    "        time.sleep(0.2)\n",
    "        driver.find_element_by_xpath('//*[@id=\"main-content\"]/div[1]/section[2]/div[1]/div/div/div[1]/button/div/div[2]').click()\n",
    "        time.sleep(0.2)\n",
    "\n",
    "        driver.find_element_by_xpath('//*[@id=\"main-content\"]/div[1]/section[2]/div[1]/div/div/div[2]/div[1]/div/div/div[1]/input').clear()\n",
    "        driver.find_element_by_xpath('//*[@id=\"main-content\"]/div[1]/section[2]/div[1]/div/div/div[2]/div[1]/div/div/div[1]/input').send_keys(start_date)\n",
    "\n",
    "        driver.find_element_by_xpath('//*[@id=\"main-content\"]/div[1]/section[2]/div[1]/div/div/div[2]/div[2]/div/div/div[1]/input').clear()\n",
    "        driver.find_element_by_xpath('//*[@id=\"main-content\"]/div[1]/section[2]/div[1]/div/div/div[2]/div[2]/div/div/div[1]/input').send_keys(end_date)\n",
    "\n",
    "        driver.find_element_by_xpath('//*[@id=\"main-content\"]/div[1]/section[2]/div[1]/div/div/div[2]/button[2]').click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        while driver.find_elements_by_xpath('//*[@id=\"main-content\"]/div[1]/section[3]/button'):\n",
    "            time.sleep(1)\n",
    "            driver.find_element_by_xpath('//*[@id=\"main-content\"]/div[1]/section[3]/button').click()\n",
    "            time.sleep(1)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        for article in soup.select('#main-content > div:nth-child(1) > section.search-results-wrapper > article'):\n",
    "            title_lst.append(article.select('div:nth-child(2) > div:nth-child(1) > div:nth-child(1) > div > a')[0].text)\n",
    "            summary_lst.append(article.select('div:nth-child(2) > div:nth-child(2) > div:nth-child(1) > div')[0].text)\n",
    "            date_lst.append(article.select('div:nth-child(2) > div:nth-child(2) > div:nth-child(2) > span')[0].text)\n",
    "    df = pd.DataFrame({'date':date_lst,'title':title_lst, 'summary':summary_lst})\n",
    "    df.to_csv(f'./crawling/WashingtonPost/news_WP_{sd}_{ed}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-185-1ef8f84b4b2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'https://www.ft.com/search?expandRefinements=true&q=oil+price&page={pp}&concept=a579350c-61ce-4c00-97ca-ddaa2e0cacf6&dateFrom={start_date}&dateTo={end_date}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0marticle\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'#site-content > div > ul > li'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# FT\n",
    "stdt = dt.datetime(2017,2,10)\n",
    "while stdt < dt.datetime(2022,2,10):\n",
    "    start_date = stdt.strftime('%Y-%m-%d')\n",
    "    sd = stdt.strftime('%Y%m%d')\n",
    "    stdt = stdt + relativedelta(months=1)\n",
    "    end_date = stdt.strftime('%Y-%m-%d')\n",
    "    ed = stdt.strftime('%Y%m%d')\n",
    "\n",
    "    url = f'https://www.ft.com/search?expandRefinements=true&q=oil+price&concept=a579350c-61ce-4c00-97ca-ddaa2e0cacf6&dateFrom={start_date}&dateTo={end_date}'\n",
    "    soup = BeautifulSoup(requests.get(url).text,'html.parser')\n",
    "    try:\n",
    "        pages = int(soup.select('#site-content > div > div.search-results__pagination > div > span')[0].text.split()[-1])\n",
    "    except:\n",
    "        pages = 1\n",
    "    title_lst = []\n",
    "    summary_lst = []\n",
    "    date_lst = []\n",
    "\n",
    "    for pp in range(1, pages+1):\n",
    "\n",
    "        url = f'https://www.ft.com/search?expandRefinements=true&q=oil+price&page={pp}&concept=a579350c-61ce-4c00-97ca-ddaa2e0cacf6&dateFrom={start_date}&dateTo={end_date}'\n",
    "        res = requests.get(url)\n",
    "        time.sleep(2)\n",
    "        soup = BeautifulSoup(res.text,'html.parser')\n",
    "        for article in soup.select('#site-content > div > ul > li'):\n",
    "            try:\n",
    "                date_lst.append(article.select('div > div > div > div:nth-child(1) > div.o-teaser__timestamp > time')[0].text)\n",
    "            except:\n",
    "                continue\n",
    "            title_lst.append(article.select('div > div > div > div:nth-child(1) > div.o-teaser__heading')[0].text)\n",
    "            try:\n",
    "                summary_lst.append(article.select('div > div > div > div:nth-child(1) > p > a > span')[0].text)\n",
    "            except:\n",
    "                summary_lst.append([])\n",
    "            \n",
    "    \n",
    "    df = pd.DataFrame({'date':date_lst,'title':title_lst, 'summary':summary_lst})\n",
    "    df.to_csv(f'./crawling/FinancialTimes/news_FT_{sd}_{ed}.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Wallstreet Journals\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import datetime as dt\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "stdt = dt.datetime(2020,6,10) # 스타트데이트타임 \n",
    "(stdt + relativedelta(months=1)).strftime('%Y%m%d') # 날짜에서 한달\n",
    "while stdt < dt.datetime(2021,11,10):\n",
    "    date_lst = []\n",
    "    title_lst = []\n",
    "    summary_lst = []\n",
    "    \n",
    "    start_date = stdt.strftime('%Y/%m/%d')\n",
    "    sd = stdt.strftime('%Y%m%d')\n",
    "    stdt = stdt + relativedelta(months=1)\n",
    "    end_date = stdt.strftime('%Y/%m/%d')\n",
    "    ed = stdt.strftime('%Y%m%d')\n",
    "    \n",
    "    url = f'https://www.wsj.com/search?query=oil%20price&isToggleOn=true&operator=AND&sort=date-desc&duration=4y&startDate={start_date}&endDate={end_date}&source=wsjie%2Cblog%2Cwsjpro%2Cautowire'\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        pages = int(driver.find_elements_by_xpath('//*[@id=\"main\"]/div[5]/div/div/div/span')[0].text.split()[1])\n",
    "    except:\n",
    "        pages = 1\n",
    "    for page in range(1, pages+1):\n",
    "        url = f'https://www.wsj.com/search?query=oil%20price&isToggleOn=true&operator=AND&sort=date-desc&duration=4y&startDate={start_date}&endDate={end_date}&source=wsjie%2Cblog%2Cwsjpro%2Cautowire&page={page}'\n",
    "        driver.get(url)\n",
    "        time.sleep(8)\n",
    "        \n",
    "        html = driver.page_source\n",
    "        #print(html[:100])\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        for article in soup.select('#main > article'):\n",
    "            title = article.select('div > div:nth-child(1) > div:nth-child(1) > div:nth-child(2) > h3 > a > span')[0].text\n",
    "            try :\n",
    "                summary = article.select('div > div:nth-child(1) > div:nth-child(1) > p > span')[0].text\n",
    "            except:\n",
    "                summary = np.nan\n",
    "            try :\n",
    "                date = article.select('div > div:nth-child(1) > div:nth-child(2) > div > p')[0].text\n",
    "            except:\n",
    "                date = np.nan\n",
    "            \n",
    "            date_lst.append(date)\n",
    "            title_lst.append(title)\n",
    "            summary_lst.append(summary)\n",
    "    df = pd.DataFrame({'date':date_lst,'title':title_lst, 'summary':summary_lst})\n",
    "    df.to_csv(f'crawling/TheWallStreetJournal/news_wsj_{sd}_{ed}.csv')\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.844,
   "position": {
    "height": "40px",
    "left": "803px",
    "right": "20px",
    "top": "117px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
